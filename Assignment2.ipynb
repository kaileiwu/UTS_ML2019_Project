{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNdVNMQNfPTZ"
   },
   "source": [
    "# Assignment 2: Practical Machine Learning Project Report\n",
    "\n",
    "\n",
    "\n",
    "31005/32513 Machine Learning Spring 2019, Assignment 2\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> Group members: Pit Wegner, Xianfeng Zhuge, Kailei Wu\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHZc_T3yf-wX"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQEvsEuOg4Zr"
   },
   "source": [
    "Nowadays, more and more activity recognition-based machine learning has been studied, especially in human physical activity recognition. The progress in this direction is surprisingly good. Models can recognize simple human exercises, such as walking, running or standing, count steps and detect a general overarching activity. However, it is hard to apply in a specific domain such as healthcare. There are mainly for two reasons: the activities themselves are more complex, potentially involving other subjects, and additionally harder to analyze because of the lack of public data that can be used within the research. In this report, we create a machine learning (ML) model regarding the \"Open Lab Nursing Activity Recognition Challenge\", which asks to recognize six different activities within the nursing area (Lago et al., 2019).\n",
    "\n",
    "In recent years, many activity recognition algorithms in health care applications are focusing on patients or doctors rather than nurses. However, the recognition of nursing activities can be helpful in the nursing domain, such as for automatic record creation and standardization of operation supervision. Until now, there is still a gap for ML models to recognize nursing-related activities due to the problems that we mentioned before. The applications of such a model would be wide-spread and of high impact in the nursing area, given the model achieves an exceptional accuracy in prediction.\n",
    "\n",
    "In this report, a machine learning technique to tackle the \"Open Lab Nursing Activity Recognition Challenge\" is proposed and evaluated. First, we will explain the data provided, including data preprocessing and data structure design. Next, the CNN model implementation that solved the problem will be presented, followed by a test result performance analysis of the model and an evaluation for the whole experiment. Before concluding, methods of improvement and future work regarding the project are formulated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bFX72tlphNQ9"
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vI6pLj7bhSGO"
   },
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhqrFrDJo09I"
   },
   "source": [
    "For training purposes, the “Open Lab Nursing Activity Recognition Challenge” (IEEEDataPort, https://www.ieee-dataport.org/competitions/nurse-care-activity-recognition-challenge) provides three sets of data from different sensors (acceleration, motion capture, meditag), labelled with 6 different nursing activities performed by 6 persons. In the experiment, only the motion capture data is used, comprised of 29 positional sensors. The dataset is split into multiple labelled segments of 60 seconds each. For each segment, the sensor positions (x, y, z coordinates) have been recorded, resulting in 87 data points and a timestamp. The activity label is inferred from a join of the segment id with the label dataset, which also includes the nurse id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-SE87VGo2lc"
   },
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8f0WbPao5fq"
   },
   "source": [
    "The data source for the project can be configured to be google drive, GitHub or the downloaded local repository. The official data source is only accessible via a regularly expiring link, inhibiting a direct download. After the download, each input file is read and saved in dataframes. To clean the dataset from NaN values, the techniques of front-filling, back-filling and finally zero-filling are used. The order is important here. Front-filling fills up missing values with the previous one, which makes sense for time series data. The back-filling afterwards fills up empty rows before the capture of the first value, padding the start. If the dataframe still includes NaN values afterwards, it must mean that there is an entire sensor missing for that segment. Then the column is filled with zeros. Since the time intervals are constant for all samples, it is also safe to remove the timestamp from the dataset and maintain ordering by the index. In order to prevent exploding and vanishing gradients, a min-max normalization step is applied before defining the final dataset. When accessing the dataset for training, the segment id is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "COLAB = True\n",
    "colab_root = '/content/' if COLAB else ''\n",
    "DATA_SOURCE = 'github' # can be google, github, or local\n",
    "location_prefix = 'data/' # path of data (or download location for github)\n",
    "\n",
    "if DATA_SOURCE == 'google':\n",
    "    from google.colab import drive\n",
    "    drive.mount(colab_root + 'drive')\n",
    "    location_prefix = colab_root + 'drive/My Drive/' + location_prefix\n",
    "elif DATA_SOURCE == 'github':\n",
    "    import urllib.request\n",
    "    \n",
    "    dl_location = colab_root + location_prefix\n",
    "    print(\"Downloading Data...\")\n",
    "    filename, headers = urllib.request.urlretrieve('https://github.com/pitwegner/UTS_ML2019_Project/archive/master.zip', filename=dl_location + 'master.zip')\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dl_location)\n",
    "    location_prefix = dl_location + 'UTS_ML2019_Project-master/data/'\n",
    "    \n",
    "# Read activity labels for segments and nurse id\n",
    "activities = pd.read_csv(location_prefix + \"activities_train.csv\")\n",
    "activity_arr = activities.activity_id.unique()\n",
    "activity_arr.sort()\n",
    "\n",
    "# Read Motion Capture Data\n",
    "mocap = pd.DataFrame()\n",
    "print(\"Reading Mocap Data\")\n",
    "i = 0\n",
    "bar_length = 50\n",
    "files = glob.glob(location_prefix + \"mocap/segment*.csv\")\n",
    "for mf in files:\n",
    "    # Basic NaN value removal\n",
    "    mocap = mocap.append(pd.read_csv(mf).ffill().bfill().fillna(0))\n",
    "    i += 1\n",
    "    progress = math.ceil(bar_length * i / len(files))\n",
    "    print(\"\\r\", \"[\" + \"=\" * progress + \" \" * (bar_length - progress) + \"] \" + \"{0:.2f}\".format(100 * i / len(files)) + '%', end=\"\")\n",
    "\n",
    "# Drop time column, since constant frequency\n",
    "mocap = mocap.reset_index().drop(columns=['index','time_elapsed'])\n",
    "\n",
    "# Min-max normalization\n",
    "mocap_normalized = (mocap-mocap.min())/(mocap.max()-mocap.min())\n",
    "mocap_normalized.segment_id = mocap.segment_id\n",
    "mocap = mocap_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  \n",
    "    def __init__(self, train, labels):\n",
    "        self.labels = labels\n",
    "        self.data = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.data[index].drop(columns=['segment_id']).values\n",
    "        sid = self.data[index].segment_id.unique()[0]\n",
    "        labels = self.labels[self.labels.segment_id == sid]\n",
    "        aid = labels.activity_id.values[0]\n",
    "        y = np.array([activity_arr.tolist().index(aid), sid])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "dataset = Dataset(mocap, activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data inspection shows the distribution of persons and activities in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Person\", \":\", \"[(activity_id, count), ...]\")\n",
    "for a in activities.subject.unique():\n",
    "    act = activities[activities.subject == a]\n",
    "    print(a, \":\", [(i, len(act[act.activity_id == i].segment_id)) for i in np.sort(act.activity_id.unique())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VFsFB6-o7Gf"
   },
   "source": [
    "### Data Split and Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reXEhFVQo86H"
   },
   "source": [
    "After the data preprocessing, two different approaches for the data split are provided: Splitting the data  randomly or splitting the data by  person. For the person split, four persons are chosen for training, one person for validation and one for testing. This results in an approximate split of 70-15-15. For a random split, the segments are shuffled and also split by the same percentages. Afterwards, the window indices are determined by the window length of 200 (twice the frequency) and the stride of 50 for each segment. By saving only the indices, memory can be saved, not  storing  redundant  information. For each resulting dataset, a RandomWindowSampler handles the access during training, selecting the window of the fixed window length from a random permutation  of the indices. This way, each window is selected exactly once per epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler    \n",
    "\n",
    "window_length = 200 # = 2*f\n",
    "\n",
    "# Sampler that iterates a random permutation of start indices and selects window\n",
    "class RandomWindowSampler(Sampler):\n",
    "  \n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (slice(self.indices[i], self.indices[i] + window_length) for i in torch.randperm(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data either randomly by segments or by person (as official test set introduces a new person)\n",
    "PERSON_SPLIT = False\n",
    "TEST_PERSON = 2\n",
    "VAL_PERSON = 4\n",
    "\n",
    "if PERSON_SPLIT:\n",
    "    indices = {}\n",
    "    for sid in dataset.data.segment_id.unique():\n",
    "        i = list(dataset.data[dataset.data.segment_id == sid].index[0:-window_length:50])\n",
    "        p = activities[activities.segment_id == sid].subject.item()\n",
    "        if p not in indices:\n",
    "            indices[p] = []\n",
    "        indices[p] += i\n",
    "\n",
    "    test_indices = indices.pop(TEST_PERSON)\n",
    "    val_indices = indices.pop(VAL_PERSON)\n",
    "    train_indices = [item for sublist in indices.values() for item in sublist]\n",
    "else:\n",
    "    segments = dataset.data.segment_id.unique()\n",
    "    np.random.shuffle(segments)\n",
    "    \n",
    "    split = int(np.floor(0.15 * len(segments))) # 70% training, 15% validation, 15% testing\n",
    "    train, val, test = segments[split+split:], segments[split:split+split], segments[:split]\n",
    "    \n",
    "    train_indices, val_indices, test_indices = ([],[],[])\n",
    "    for sid in train:\n",
    "        train_indices += list(dataset.data[dataset.data.segment_id == sid].index[0:-window_length:50])\n",
    "    for sid in val:\n",
    "        val_indices += list(dataset.data[dataset.data.segment_id == sid].index[0:-window_length:50])\n",
    "    for sid in test:\n",
    "        test_indices += list(dataset.data[dataset.data.segment_id == sid].index[0:-window_length:50])\n",
    "\n",
    "train_sampler = RandomWindowSampler(train_indices)\n",
    "val_sampler = RandomWindowSampler(val_indices)\n",
    "test_sampler = RandomWindowSampler(test_indices)\n",
    "\n",
    "# Create data loaders to parallelize batch training to multiple cores\n",
    "def get_train_loader(batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=3)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler, num_workers=3)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=4, sampler=test_sampler, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8L7fSIqo-xP"
   },
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90jvCtr6pBHn"
   },
   "source": [
    "The model architecture is a Convolutional Neural Network (CNN) including a convolutional layer, a pooling layer and two fully connected layers. The RELU activation function is used on both the convolution layer and the fully connected layer. The loss function we used for training and validation loss is cross-entropy loss, a standard for multi-class classification. As an optimizer, adaptive moment estimation (ADAM) was applied.\n",
    "\n",
    "\n",
    "![Architecture](https://raw.githubusercontent.com/pitwegner/UTS_ML2019_Project/master/img/architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        kernel_size = 3\n",
    "        stride = 1\n",
    "        padding = 1\n",
    "        output_channels = 24\n",
    "        \n",
    "        pooling_size = 2\n",
    "        pooling_stride = 2\n",
    "        pooling_padding = 0\n",
    "        hidden_parameters = 64\n",
    "        \n",
    "        # Calculate output size after convolution\n",
    "        conv_output_x = int((dataset[0:1][0].shape[0] - kernel_size + 2 * padding) / stride) + 1\n",
    "        conv_output_y = int((dataset[0:1][0].shape[1] - kernel_size + 2 * padding) / stride) + 1\n",
    "        pool_output_x = int((conv_output_x - pooling_size + 2 * pooling_padding) / pooling_stride) + 1\n",
    "        pool_output_y = int((conv_output_y - pooling_size + 2 * pooling_padding) / pooling_stride) + 1\n",
    "        self.dense_input = output_channels * pool_output_x * pool_output_y\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, output_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=pooling_size, stride=pooling_stride, padding=pooling_padding)\n",
    "        self.fc1 = torch.nn.Linear(self.dense_input, hidden_parameters)\n",
    "        self.fc2 = torch.nn.Linear(hidden_parameters, len(activity_arr))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.dense_input)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFdyE-wZpCw5"
   },
   "source": [
    "### Test Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbAYv5pHpEg9"
   },
   "source": [
    "As an activity recognition model, the accuracy of the model is measured by its classification  performance. The challenge requires to predict the activity of a given segment. In  order  to  test the model accuracy, the activity for each window is predicted and compared to the label  data. The final test aggregates the predicitions for each segment, selecting the mode as a final decision (majority vote). The  results are  compared to the activity labels to compute the overall accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def testNet(net):\n",
    "    confusion_matrix = np.zeros((6,6))\n",
    "    votes = {}\n",
    "    print(\"Starting Test Run\")\n",
    "\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape((inputs.shape[0], 1, inputs.shape[1], inputs.shape[2]))\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        val_outputs = net(inputs)\n",
    "        predictions = val_outputs.argmax(1)\n",
    "\n",
    "        # Collect votes\n",
    "        for s in range(len(labels)):\n",
    "            segment = labels[s,1].item()\n",
    "            if segment not in votes:\n",
    "                votes[segment] = []\n",
    "            votes[segment].append(predictions[s].item())\n",
    "\n",
    "        # Compare test vs. label\n",
    "        confusion_matrix[predictions, labels[:,0]] += 1\n",
    "        print(\"\\r\", \"{0:.2f}%\".format(100 * i / len(test_loader)), end=\"\")\n",
    "\n",
    "    # Select prediction as vote majority\n",
    "    correct_votes = 0\n",
    "    for sid in votes:\n",
    "        label = dataset.labels[dataset.labels.segment_id == sid].activity_id.values[0]\n",
    "        votes[sid] = [activity_arr[stats.mode(votes[sid])[0][0]], label]\n",
    "        correct_votes += int(votes[sid][0] == votes[sid][1])\n",
    "\n",
    "    print(\"\\r\", \"Confusion matrix for individual windows:\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"Accuracy: {0:.2f}%\".format(100 * np.trace(confusion_matrix)/np.sum(confusion_matrix)))\n",
    "    print(\"\\r\", \"Vote prediction for entire segments:\")\n",
    "    print(votes)\n",
    "    print(\"Accuracy: {0:.2f}%\".format(100 * correct_votes/len(votes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rxdg99fYhS07"
   },
   "source": [
    "## Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foyYYjXKoqbr"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRKcINedhTGl"
   },
   "source": [
    "training: \n",
    "\n",
    "1. input the data \n",
    "2. mini batch: size 32\n",
    "3. learning rate 0.000001\n",
    "4. forward pass, backward pass, optimize\n",
    "5. at the end of each epoch, we did validation(see the validation loss)\n",
    "6. stop learning if valodation loss is not decrease for 10 epoch\n",
    "\n",
    "testing: \n",
    "\n",
    "1. forward pass for test data set.\n",
    "2. conpare to the labels, create confusion matrix, calculate the accuracy. \n",
    "3. majority vote for siugments, select the mode, calculate the accuracy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tONIZV0ohTS3"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_tOUGIxhTaL"
   },
   "source": [
    "### Model Performance\n",
    "\n",
    "![Random_Segment_Split](https://raw.githubusercontent.com/pitwegner/UTS_ML2019_Project/master/img/plot_random_segment_split.png)\n",
    "Split randomly by segments\n",
    "\n",
    "|     *    | $l_2$ | $l_3$ | $l_4$ | $l_6$ | $l_9$ | $l_{12}$ |\n",
    "| -------- | ----- | ----- | ----- | ----- | ----- | -------- |\n",
    "| $p_2$    |   366 |   103 |    68 |   185 |    61 |       39 |\n",
    "| $p_3$    |    88 |   411 |    36 |     4 |     5 |        3 |\n",
    "| $p_4$    |    83 |    80 |   181 |    49 |   210 |       62 |\n",
    "| $p_6$    |    25 |    25 |     2 |   146 |    74 |       92 |\n",
    "| $p_9$    |    39 |     4 |     6 |    32 |   269 |      103 |\n",
    "| $p_{12}$ |   171 |    10 |    21 |    27 |   142 |      688 |\n",
    " \n",
    "Accuracy: 52.71%\n",
    "\n",
    "Entire segments:\n",
    "\n",
    "| segment | 4 | 31 | 56 | 57 | 63 | 88 | 101 | 173 | 185 | 194 | 215 | 227 | 241 | 248 | 290 | 295 | 305 | 306 | 336 | 362 | 373 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| label | 2 | 4 | 12 | 2 | 2 | 2 | 6 | 9 | 9 | 12 | 3 | 9 | 2 | 3 | 4 | 12 | 3 | 12 | 9 | 3 | 9 |\n",
    "| predict | 2 | 2 | 12 | 2 | 4 | 2 | 2 | 9 | 9 | 12 | 2 | 12 | 2 | 3 | 4 | 12 | 3 | 12 | 6 | 3 | 9 |\n",
    "| **segment** | **385** | **480** | **508** | **515** | **531** | **559** | **573** | **607** | **620** | **631** | **639** | **640** | **667** | **689** | **703** | **711** | **748** | **753** | **765** | **777** | **795** |\n",
    "| label | 3 | 2 | 6 | 9 | 6 | 12 | 3 | 6 | 3 | 12 | 12 | 12 | 12 | 2 | 9 | 12 | 2 | 4 | 9 | 12 | 12 |\n",
    "| predict | 3 | 12 | 4 | 12 | 2 | 12 | 3 | 6 | 4 | 12 | 12 | 12 | 12 | 2 | 4 | 12 | 2 | 4 | 9 | 12 | 12 |\n",
    "\n",
    "Accuracy 71.43%\n",
    "\n",
    "![Person_Split](https://raw.githubusercontent.com/pitwegner/UTS_ML2019_Project/master/img/plot_person_split.png)\n",
    "Split by Person\n",
    "\n",
    "|     *    | $l_2$ | $l_3$ | $l_4$ | $l_6$ | $l_9$ | $l_{12}$ |\n",
    "| -------- | ----- | ----- | ----- | ----- | ----- | -------- |\n",
    "| $p_2$    |   186 |   212 |   205 |   231 |    78 |      148 |\n",
    "| $p_3$    |    60 |   305 |    34 |     0 |     3 |        0 |\n",
    "| $p_4$    |    46 |    58 |   126 |    17 |    81 |      118 |\n",
    "| $p_6$    |     7 |    18 |     0 |    45 |    33 |       49 |\n",
    "| $p_9$    |    51 |   103 |   104 |    13 |   207 |      118 |\n",
    "| $p_{12}$ |   371 |   437 |    78 |   122 |   138 |      451 |\n",
    "\n",
    "Accuracy: 31.04%\n",
    "\n",
    "Entire segments:\n",
    "\n",
    "| segment | 0 | 56 | 67 | 85 | 99 | 138 | 143 | 144 | 145 | 189 | 196 | 200 | 210 | 213 | 219 | 227 | 229 | 243 | 283 | 305 | 328 |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| label | 6 | 12 | 12 | 2 | 3 | 3 | 3 | 4 | 12 | 6 | 2 | 9 | 9 | 3 | 2 | 9 | 2 | 9 | 4 | 3 | 3 |\n",
    "| predict | 2 | 12 | 12 | 2 | 3 | 12 | 2 | 2 | 12 | 2 | 12 | 12 | 12 | 12 | 12 | 9 | 2 | 9 | 2 | 2 | 12 |\n",
    "| **segment** | **340** | **380** | **387** | **406** | **432** | **441** | **459** | **515** | **604** | **612** | **613** | **625** | **639** | **662** | **669** | **674** | **680** | **682** | **685** | **686** | **723** | **773** |\n",
    "| label | 12 | 9 | 12 | 4 | 12 | 12 | 3 | 9 | 12 | 3 | 2 | 4 | 12 | 3 | 4 | 3 | 6 | 2 | 2 | 12 | 6 | 3 |\n",
    "| predict | 12 | 2 | 12 | 2 | 12 | 12 | 12 | 9 | 12 | 2 | 2 | 9 | 12 | 3 | 4 | 3 | 2 | 12 | 12 | 4 | 2 | 12 |\n",
    "\n",
    "Accuracy: 44.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_135wN0hTe8"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJHpJvsvhTli"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtcC0IahmoHv"
   },
   "source": [
    "## Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OqpS59Emva8"
   },
   "source": [
    "As a machine learning model, common ethical issues considering the application in a real world domain arise naturally. These typically aim at potential mistakes, training bias and data protection. Escpecially in the medical domain, mistakes can have a huge impact on a human life. In the case of our model, however, a wrong documentation entry about a nurse activity has a limited capability to directly cause damage. Patient health can be compromised by a left out or wrong procedure, for example developing pressure ulcers as a result of improper turning and repositioning of bedridden patients. The documentation record can then be used to trace back where the mistake has happened. Thus, our model provides support in preventing and retracing clinical incidents without directly impacting patient safety. Additionally, giving the nurse a chance to manually adjust the report after its generation further mitigates the impact of erroneous results. Other benefits of applying the model in nursing include a decreased workload and a more complete activity report for accounting purposes.\n",
    "\n",
    "Activity recognition in a workplace also adds ethical complications. If not protected, tool could easily be (mis-)used by managers to monitor workforce activity, intruding into their privacy. The insights could result in different treatment for individual employees, even up to terminating the employment. Privacy impairment from the data pool itself is a further issue, since detailed movements are possibly visible from motion capture data, even if much harder to process than, say video. Thus, secure storage and access to data, as well as a proper authorization to the model results are crucial for an implementation.\n",
    "\n",
    "Considering the results being biased toward training data, the risk of discrimination only leads to more inaccurate results for new employees. As this is known and can be tested beforehand, the impact is minimal. Overall, with proper data protection and sufficient accuracy, the benefits of the technique outweigh the possible risks. From a utalitarian point of view, the use of our model can hence be considered ethically acceptable. A deontological approach also does not object. Since results can be modified, the autonomy and freedom of will are not inhibited by applying the model, as long as privacy is ensured. Furthermore, the universalization of the application neither contradict with the intention nor with itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Y4XeiVri2XH"
   },
   "outputs": [],
   "source": [
    "d = {625: [9, 4], 138: [12, 3], 196: [12, 2], 613: [2, 2], 243: [9, 9], 387: [12, 12], 459: [12, 3], 0: [2, 6], 432: [12, 12], 99: [3, 3], 612: [2, 3], 305: [2, 3], 328: [12, 3], 143: [2, 3], 639: [12, 12], 144: [2, 4], 680: [2, 6], 515: [9, 9], 145: [12, 12], 685: [12, 2], 213: [12, 3], 674: [3, 3], 682: [12, 2], 56: [12, 12], 773: [12, 3], 604: [12, 12], 189: [2, 6], 723: [2, 6], 200: [12, 9], 85: [2, 2], 227: [9, 9], 669: [4, 4], 219: [12, 2], 380: [2, 9], 67: [12, 12], 406: [2, 4], 662: [3, 3], 210: [12, 9], 340: [12, 12], 283: [2, 4], 686: [4, 12], 441: [12, 12], 229: [2, 2]}\n",
    "s = '| segment |'\n",
    "for k in sorted(d.keys())[:len(d.keys())//2]:\n",
    "    s += ' {} |'.format(k)\n",
    "s += \"\\n| - |\"\n",
    "for k in sorted(d.keys())[:len(d.keys())//2]:\n",
    "    s += ' - |'\n",
    "s += \"\\n| label |\"\n",
    "for k in sorted(d.keys())[:len(d.keys())//2]:\n",
    "    s += ' {} |'.format(d[k][1])\n",
    "s += '\\n| predict |'\n",
    "for k in sorted(d.keys())[:len(d.keys())//2]:\n",
    "    s += ' {} |'.format(d[k][0])\n",
    "s += '\\n| **segment** |'\n",
    "for k in sorted(d.keys())[len(d.keys())//2:]:\n",
    "    s += ' **{}** |'.format(k)\n",
    "s += \"\\n| label |\"\n",
    "for k in sorted(d.keys())[len(d.keys())//2:]:\n",
    "    s += ' {} |'.format(d[k][1])\n",
    "s += '\\n| predict |'\n",
    "for k in sorted(d.keys())[len(d.keys())//2:]:\n",
    "    s += ' {} |'.format(d[k][0])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICbOH0n8mX34"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
