{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "A2_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzn2si-aysUL",
        "colab_type": "text"
      },
      "source": [
        "## Notes\n",
        "\n",
        "* All segments have different lengths -> sliding window approach\n",
        "  * maybe length of 100 or 200? I read that the window size matters a lot\n",
        "\n",
        "## Open Questions\n",
        "\n",
        "* Network architecture? -> LSTM, CNN, Hierarchical Attention?\n",
        "  * Maybe implement multiple and compare?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReiUL--rysUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-RL7JyBysUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activities = pd.read_csv(\"/content/drive/My Drive/train/activities_train.csv\") # Activity Labels for Segments and Nurse ID\n",
        "mocap = pd.DataFrame()\n",
        "print(\"Reading Mocap Data\")\n",
        "i = 0\n",
        "bar_length = 50\n",
        "files = glob.glob(\"/content/drive/My Drive/train/mocap/segment*.csv\")\n",
        "for mf in files:\n",
        "    i += 1\n",
        "    progress = math.ceil(bar_length * i / len(files))\n",
        "    print(\"\\r\", \"[\" + \"=\" * progress + \" \" * (bar_length - progress) + \"] \" + \"{0:.2f}\".format(100 * i / len(files)) + '%', end=\"\")\n",
        "    mocap = mocap.append(pd.read_csv(mf).ffill().bfill().fillna(0))\n",
        "mocap = mocap.reset_index().drop(columns=['index','time_elapsed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM-losmrzvIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mocap_normalized = (mocap-mocap.min())/(mocap.max()-mocap.min())\n",
        "mocap_normalized.segment_id = mocap.segment_id\n",
        "mocap = mocap_normalized\n",
        "activity_arr = activities.activity_id.unique()\n",
        "activity_arr.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8N1M0M0W2_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  \n",
        "  def __init__(self, train, labels):\n",
        "        self.labels = labels\n",
        "        self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        X = self.train[index].drop(columns=['segment_id']).values\n",
        "        sid = self.train[index].segment_id.unique()[0]\n",
        "        labels = self.labels[self.labels.segment_id == sid]\n",
        "        aid = labels.activity_id.values[0]\n",
        "        y = activity_arr.tolist().index(aid)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "dataset = Dataset(mocap, activities)\n",
        "window_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-qq2hNXysVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleCNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        self.kernel_size = 3\n",
        "        self.stride = 1\n",
        "        self.padding = 1\n",
        "        self.output_channels = 24\n",
        "        self.hidden_parameters = 64\n",
        "        \n",
        "        self.output_x = int((window_length - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
        "        self.output_y = int((dataset[0:1][0].shape[1] - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(1, self.output_channels, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = torch.nn.Linear(self.output_channels * int(self.output_x / 2) * int(self.output_y / 2), self.hidden_parameters)\n",
        "        self.fc2 = torch.nn.Linear(self.hidden_parameters, len(activities.activity_id.unique()))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, self.output_channels * int(self.output_x / 2) * int(self.output_y / 2))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9yWA08P7wFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import Sampler    \n",
        "\n",
        "class RandomWindowSampler(Sampler):\n",
        "  \n",
        "  def __init__(self, data_source):\n",
        "    self.data = data_source\n",
        "    self.indices = []\n",
        "    for sid in data_source.segment_id.unique():\n",
        "      self.indices += list(data_source[data_source.segment_id == sid].index[:-window_length])\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return (slice(self.indices[i], self.indices[i] + window_length) for i in torch.randperm(len(self.indices)))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.indices)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdZrZemGHkB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = RandomWindowSampler(mocap)\n",
        "val_sampler = RandomWindowSampler(mocap)\n",
        "test_sampler = RandomWindowSampler(mocap)\n",
        "\n",
        "def get_train_loader(batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "    return(train_loader)\n",
        "  \n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size=4, sampler=test_sampler, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB02w7U8IJK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    \n",
        "    #Loss function\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    \n",
        "    #Optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return(loss, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvSGvD2I5JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
        "  \n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_batches = len(train_loader)\n",
        "    \n",
        "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    \n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs.reshape((32,1,200,87))), Variable(labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            loss_size = loss(outputs, labels.long())\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #Print statistics\n",
        "            running_loss += loss_size.data.item()\n",
        "            total_train_loss += loss_size.data.item()\n",
        "            \n",
        "            #Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                #Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            \n",
        "        #At the end of the epoch, do a pass on the validation set\n",
        "        total_val_loss = 0\n",
        "        for inputs, labels in val_loader:\n",
        "            \n",
        "            #Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Forward pass\n",
        "            val_outputs = net(inputs)\n",
        "            val_loss_size = loss(val_outputs, labels)\n",
        "            total_val_loss += val_loss_size.data[0]\n",
        "            \n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "        \n",
        "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCwSnqOBJerf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN = SimpleCNN()\n",
        "trainNet(CNN.double(), batch_size=32, n_epochs=5, learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cigZzw7XcGy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}